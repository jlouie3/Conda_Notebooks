{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Collaborative filtering: Choose top N books to recommend to a user\n",
    "\n",
    "\n",
    "Process:\n",
    "    1. Find K nearest neighbors of a user\n",
    "    2. Fill in unrated products by taking a weighted average of nearest neighbors that have rated the product (more similar = more weight)\n",
    "    3. Sort unrated products by their estimated ratings in descending order\n",
    "    4. Pick top 10\n",
    "\n",
    "Workflow:\n",
    "    1. Set up the data\n",
    "    2. Construct a rating matrix\n",
    "    3. Find K nearest neighbors\n",
    "    4. Find top N recommendations\n",
    "\n",
    "Distance metrics\n",
    "    - Euclidean distance\n",
    "    - Correlation distance = 1 - correlation\n",
    "    - Hamming distance (how many numbers match) = % of numbers in disagreement\n",
    "\n",
    "\n",
    "Data source: http://www2.informatik.uni-freiburg.de/~cziegler/BX/\n",
    "'''\n",
    "\n",
    "'''\n",
    "Latent Factor Analysis\n",
    "\n",
    "    Split UserProduct matrix into 2 tables, one for users, the other for products\n",
    "        - UserProduct = [User] * [Product]\n",
    "        - [User] = Users x Factors describing user\n",
    "        - [Product] = Products x Factors describing product\n",
    "        - In UserProduct matrix, rating is equal to matrix product of User*Product for that user and product\n",
    "    \n",
    "    Standard optimization used in Gradient Descent\n",
    "        R = P*Q\n",
    "        Error(u,i) = R(u,i) - (P(u) * Q(i))\n",
    "        Total Square Error = SUM((R(u,i) - (P(u) * Q(i)))^2) # sum of squared error\n",
    "        MIN(total square error) # want to minimize square error\n",
    "        Regularization Term = lambda * (||P(u)||^2 + ||Q(i)||^2) # used to prevent overfitting\n",
    "    \n",
    "        => MIN(SUM(square error + regularization term))\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (1149780, 3)\n",
      "Data shape after removing inconsistencies: (1031175, 3)\n",
      "(405709, 3)\n"
     ]
    }
   ],
   "source": [
    "# Get data (same process as Collaborative_Filtering_KNN.ipynb)\n",
    "import pandas as pd\n",
    "\n",
    "dataFile = 'data/BX-Book-Ratings.csv'\n",
    "data = pd.read_csv(dataFile, sep=';', header=0, names=[\"user\",\"isbn\",\"rating\"], encoding='ANSI')\n",
    "\n",
    "bookFile = 'data/BX-Books.csv'\n",
    "books = pd.read_csv(bookFile, sep=';', header=0, names=[\"isbn\",\"title\",\"author\"], encoding='ANSI', error_bad_lines=False, usecols=[0,1,2], index_col=0)\n",
    "\n",
    "# Get rid of any inconsistent ISBN's since data is not perfect\n",
    "original_size = data.shape\n",
    "data = data[data[\"isbn\"].isin(books.index)]\n",
    "new_size = data.shape\n",
    "\n",
    "print('Original data shape: {}'.format(original_size))\n",
    "print('Data shape after removing inconsistencies: {}'.format(new_size))\n",
    "\n",
    "# Get number of users per ISBN\n",
    "usersPerISBN = data.isbn.value_counts()\n",
    "# ISBNs per user\n",
    "ISBNsPerUser = data.user.value_counts()\n",
    "\n",
    "# Reduce sparsity of data matrix by:\n",
    "#   - excluding any isbns that have less than 10 users/ratings\n",
    "#   - excluding any users that have less than 10 books read\n",
    "data = data[data[\"isbn\"].isin(usersPerISBN[usersPerISBN > 10].index)]\n",
    "data = data[data[\"user\"].isin(ISBNsPerUser[ISBNsPerUser > 10].index)]\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R.data[0] = 0.0\n",
      "R.row[0] = 10633\n",
      "R.col[0] = 3053\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "# Create internal map of UserIDs to integer codes\n",
    "data['user'] = data['user'].astype(\"category\")\n",
    "data['isbn'] = data['isbn'].astype(\"category\")\n",
    "\n",
    "# coo_matrix((values, (row_source, column_source)))\n",
    "R = coo_matrix((data['rating'].astype(float),\n",
    "                    (data['user'].cat.codes.copy(),\n",
    "                     data['isbn'].cat.codes.copy())))\n",
    "\n",
    "# Can read from coo_matrix like so: \n",
    "print('R.data[0] = {}'.format(R.data[0]))\n",
    "print('R.row[0] = {}'.format(R.row[0]))\n",
    "print('R.col[0] = {}'.format(R.col[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19513914.866341911"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# M = number of users, N = number of ISBNs\n",
    "M,N = R.shape\n",
    "# K = number of factors\n",
    "K = 3\n",
    "\n",
    "import numpy as np\n",
    "P = np.random.rand(M,K) # Initialize values for P and Q\n",
    "Q = np.random.rand(K,N)\n",
    "\n",
    "from numpy.linalg import norm\n",
    "def error(R,P,Q,lamda=0.02):\n",
    "    ratings = R.data\n",
    "    rows = R.row\n",
    "    cols = R.col\n",
    "    e = 0\n",
    "    for ui in range(len(ratings)):\n",
    "        rui = ratings[ui]\n",
    "        u = rows[ui]\n",
    "        i = cols[ui]\n",
    "        if rui > 0:\n",
    "            e = e + pow(rui - np.dot(P[u,:],Q[:,i]), 2) +\\\n",
    "                lamda * (pow(norm(P[u,:]), 2) + pow(norm(Q[:,i]), 2))\n",
    "    \n",
    "    return e\n",
    "\n",
    "# Calculate error\n",
    "error(R,P,Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.3501678589274633"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = np.sqrt(error(R,P,Q) / len(R.data))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stochaisticGradientDescent(R, K, lamda=0.02, steps=10, gamma=0.001, threshold=0.5):\n",
    "    '''\n",
    "    Uses Stochaistic Gradient descent to calculate P,Q matrices and minimize RMSE\n",
    "    \n",
    "        1. Set max # of iterations to perform gradient descent\n",
    "        2. Initial P,Q matrices using random values\n",
    "        3. Begin gradient descent loop\n",
    "            - Calculate error between R[ui] and P[u]*Q[i]\n",
    "            - Update P by small value: P = P + gamma * (partial derivative of error function in terms of P)\n",
    "            - Update Q by small value: Q = Q + gamma * (partial derivative of error function in terms of Q)\n",
    "            - Notes:\n",
    "                - gamma = learning constant\n",
    "                - lambda = regularization factor\n",
    "                - error = (R(u,i)-(P(u)*Q(i)))^2 + lambda*(||P(u)||^2+||Q(i)||^2)\n",
    "        4. If completed max number of iterations or RMSE is below threshold, end gradient descent\n",
    "        5. Return P,Q\n",
    "        \n",
    "    param R: table with (partially) filled data\n",
    "    param K: number of factors\n",
    "    param lamda: regularization factor\n",
    "    param steps: max number of iterations to perform gradient descent\n",
    "    param gamma: learning rate\n",
    "    param threshold: satisfactory rmse in which gradient descent can be stopped\n",
    "    '''\n",
    "    \n",
    "    M,N = R.shape\n",
    "    P = np.random.rand(M,K) # Initialize values for P and Q\n",
    "    Q = np.random.rand(K,N)\n",
    "    \n",
    "    rmse = np.sqrt(error(R,P,Q) / len(R.data))\n",
    "    print('Initial RMSE: {}'.format(rmse))\n",
    "    \n",
    "    for step in range(steps): \n",
    "        print('Executing step {}...'.format(step))\n",
    "        for ui in range(len(R.data)):\n",
    "            rui = R.data[ui]\n",
    "            u = R.row[ui]\n",
    "            i = R.col[ui]\n",
    "            \n",
    "            if rui > 0:\n",
    "                eui = rui - np.dot(P[u,:],Q[:,i])\n",
    "                P[u,:] = P[u,:] + gamma * 2 * (eui * Q[:,i] - lamda * P[u,:]) # Partial derivative of error function in terms of P\n",
    "                Q[:,i] = Q[:,i] + gamma * 2 * (eui * P[u,:] - lamda * Q[:,i]) # Partial derivative of error function in terms of Q\n",
    "        \n",
    "        rmse = np.sqrt(error(R,P,Q) / len(R.data))\n",
    "        if rmse < threshold:\n",
    "            break\n",
    "            \n",
    "    print('Final RMSE: {}'.format(rmse))\n",
    "    return P,Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial RMSE: 4.327172212249701\n",
      "Executing step 0...\n",
      "Executing step 1...\n",
      "Executing step 2...\n",
      "Executing step 3...\n",
      "Executing step 4...\n",
      "Executing step 5...\n",
      "Executing step 6...\n",
      "Executing step 7...\n",
      "Executing step 8...\n",
      "Executing step 9...\n",
      "Executing step 10...\n",
      "Executing step 11...\n",
      "Executing step 12...\n",
      "Executing step 13...\n",
      "Executing step 14...\n",
      "Executing step 15...\n",
      "Executing step 16...\n",
      "Executing step 17...\n",
      "Executing step 18...\n",
      "Executing step 19...\n",
      "Executing step 20...\n",
      "Executing step 21...\n",
      "Executing step 22...\n",
      "Executing step 23...\n",
      "Executing step 24...\n",
      "Executing step 25...\n",
      "Executing step 26...\n",
      "Executing step 27...\n",
      "Executing step 28...\n",
      "Executing step 29...\n",
      "Executing step 30...\n",
      "Executing step 31...\n",
      "Executing step 32...\n",
      "Executing step 33...\n",
      "Executing step 34...\n",
      "Executing step 35...\n",
      "Executing step 36...\n",
      "Executing step 37...\n",
      "Executing step 38...\n",
      "Executing step 39...\n",
      "Executing step 40...\n",
      "Executing step 41...\n",
      "Executing step 42...\n",
      "Executing step 43...\n",
      "Executing step 44...\n",
      "Executing step 45...\n",
      "Executing step 46...\n",
      "Executing step 47...\n",
      "Executing step 48...\n",
      "Executing step 49...\n",
      "Executing step 50...\n",
      "Executing step 51...\n",
      "Executing step 52...\n",
      "Executing step 53...\n",
      "Executing step 54...\n",
      "Executing step 55...\n",
      "Executing step 56...\n",
      "Executing step 57...\n",
      "Executing step 58...\n",
      "Executing step 59...\n",
      "Executing step 60...\n",
      "Executing step 61...\n",
      "Executing step 62...\n",
      "Executing step 63...\n",
      "Executing step 64...\n",
      "Executing step 65...\n",
      "Executing step 66...\n",
      "Executing step 67...\n",
      "Executing step 68...\n",
      "Executing step 69...\n",
      "Executing step 70...\n",
      "Executing step 71...\n",
      "Executing step 72...\n",
      "Executing step 73...\n",
      "Executing step 74...\n",
      "Executing step 75...\n",
      "Executing step 76...\n",
      "Executing step 77...\n",
      "Executing step 78...\n",
      "Executing step 79...\n",
      "Executing step 80...\n",
      "Executing step 81...\n",
      "Executing step 82...\n",
      "Executing step 83...\n",
      "Executing step 84...\n",
      "Executing step 85...\n",
      "Executing step 86...\n",
      "Executing step 87...\n",
      "Executing step 88...\n",
      "Executing step 89...\n",
      "Executing step 90...\n",
      "Executing step 91...\n",
      "Executing step 92...\n",
      "Executing step 93...\n",
      "Executing step 94...\n",
      "Executing step 95...\n",
      "Executing step 96...\n",
      "Executing step 97...\n",
      "Executing step 98...\n",
      "Executing step 99...\n",
      "Final RMSE: 0.8224431151118085\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.72587866,  1.38930468],\n",
       "        [ 2.04571476,  1.87924749],\n",
       "        [ 2.18914234,  2.5119368 ],\n",
       "        ..., \n",
       "        [ 0.9062367 ,  0.59521126],\n",
       "        [ 2.3074146 ,  2.10651759],\n",
       "        [ 1.14989965,  1.96354295]]),\n",
       " array([[ 1.60545525,  2.21989211,  1.96204847, ...,  2.56073085,\n",
       "          2.62108258,  0.48051239],\n",
       "        [ 2.06939785,  1.94346057,  1.77563545, ...,  2.01334575,\n",
       "          1.71514793,  0.55561289]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stochaisticGradientDescent(R,K=2,gamma=0.0007,lamda=0.01,steps=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

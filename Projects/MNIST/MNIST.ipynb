{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Classifying the MNIST Dataset with Keras\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is GPU available? False\n",
      "List of GPUs:  []\n",
      "List of devices: \n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 9597230160833706048\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 1060424767575803676\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 9810048291066593611\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.python.client import device_lib\n",
    "print(\"Is GPU available? {0}\".format(tf.test.is_gpu_available()))\n",
    "\n",
    "local_device_protos = device_lib.list_local_devices()\n",
    "print(\"List of GPUs: \", [x.name for x in local_device_protos if x.device_type == 'GPU'])\n",
    "\n",
    "print(\"List of devices: \")\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Load MNIST dataset\n",
    "# 60000 handwritten drawings of digits, uploaded as 28x28 greyscale images \n",
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Describe the data\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "num_classes = 10  # classifying numbers between 0-9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pipeline\n",
    "---\n",
    "Data is modified to a format that can be used to train the model or be evaluated by the model\n",
    "* Reshape\n",
    "* Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow by default supports the ndarray format: \n",
    "#    NHWC (Number of samples, Height of each sample, Width of each sample, # of channels)\n",
    "# Need to convert input data from NHW to NHWC, where C=1 because images are greyscale\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "# Define input shape of a single record\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "# Normalize input data\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# Convert labels from multi-class values to one-hot encoded vectors\n",
    "#  3 => 0 0 0 1 0 0 0 0 0 0 and 1 => 0 1 0 0 0 0 0 0 0 0 \n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 26, 26, 64)\n",
      "(None, 24, 24, 32)\n",
      "(None, 12, 12, 32)\n",
      "(None, 4608)\n",
      "(None, 4608)\n",
      "(None, 10)\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 0.1702 - acc: 0.9473 - val_loss: 0.0526 - val_acc: 0.9832\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 0.0759 - acc: 0.9770 - val_loss: 0.0501 - val_acc: 0.9838\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 0.0590 - acc: 0.9816 - val_loss: 0.0383 - val_acc: 0.9868\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 0.0498 - acc: 0.9842 - val_loss: 0.0361 - val_acc: 0.9883\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 0.0455 - acc: 0.9854 - val_loss: 0.0361 - val_acc: 0.9884\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.0409 - acc: 0.9873 - val_loss: 0.0339 - val_acc: 0.9886\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 0.0384 - acc: 0.9871 - val_loss: 0.0322 - val_acc: 0.9901\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 0.0340 - acc: 0.9890 - val_loss: 0.0334 - val_acc: 0.9898\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.0326 - acc: 0.9894 - val_loss: 0.0307 - val_acc: 0.9901\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.0296 - acc: 0.9904 - val_loss: 0.0328 - val_acc: 0.9895\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 0.0285 - acc: 0.9908 - val_loss: 0.0325 - val_acc: 0.9904\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 0.0280 - acc: 0.9907 - val_loss: 0.0346 - val_acc: 0.9901\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.0259 - acc: 0.9915 - val_loss: 0.0329 - val_acc: 0.9906\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 0.0255 - acc: 0.9923 - val_loss: 0.0347 - val_acc: 0.9901\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 0.0236 - acc: 0.9918 - val_loss: 0.0323 - val_acc: 0.9902\n",
      "Test loss: 0.03233218331732205\n",
      "Test accuracy: 0.9902\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dropout, Softmax\n",
    "from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layer=Conv2D(64, kernel_size=(3,3),\n",
    "                       activation='relu',\n",
    "                       input_shape=input_shape))\n",
    "print(model.output_shape)\n",
    "model.add(layer=Conv2D(32, kernel_size=(3,3),\n",
    "                       activation='relu'))\n",
    "print(model.output_shape)\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "print(model.output_shape)\n",
    "model.add(Flatten())\n",
    "print(model.output_shape)\n",
    "model.add(Dropout(0.5))\n",
    "print(model.output_shape)\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "print(model.output_shape)\n",
    "\n",
    "#   define compile to minimize categorical loss, use ada delta optimized, and optimize to maximizing accuracy\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#   Train the model and test/validate the mode with the test data after each cycle (epoch) through the training data\n",
    "#   Return history of loss and accuracy for each epoch\n",
    "batch_size = 20\n",
    "epochs = 20\n",
    "cbk_early_stopping = EarlyStopping(monitor='val_acc', patience=2, mode='max')\n",
    "\n",
    "hist = model.fit(x_train, y_train,\n",
    "                 batch_size=batch_size,\n",
    "                 epochs=epochs,\n",
    "                 verbose=1,\n",
    "                 validation_data=(x_test, y_test), \n",
    "                 callbacks=[cbk_early_stopping])\n",
    "\n",
    "#   Evaluate the model with the test data to get the scores on \"real\" data.\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 26, 26, 32)\n",
      "(None, 21632)\n",
      "(None, 10)\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.1615 - acc: 0.9519 - val_loss: 0.0804 - val_acc: 0.9737\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.0637 - acc: 0.9811 - val_loss: 0.0644 - val_acc: 0.9789\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.0448 - acc: 0.9861 - val_loss: 0.0604 - val_acc: 0.9809\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.0324 - acc: 0.9902 - val_loss: 0.0593 - val_acc: 0.9818\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.0237 - acc: 0.9925 - val_loss: 0.0637 - val_acc: 0.9815\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.0173 - acc: 0.9942 - val_loss: 0.0745 - val_acc: 0.9805\n",
      "Test loss: 0.07452482019617164\n",
      "Test accuracy: 0.9805\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dropout, Softmax\n",
    "from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layer=Conv2D(32, kernel_size=(3,3),\n",
    "                       activation='relu',\n",
    "                       input_shape=input_shape))\n",
    "print(model.output_shape)\n",
    "model.add(Flatten())\n",
    "print(model.output_shape)\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "print(model.output_shape)\n",
    "\n",
    "#   define compile to minimize categorical loss, use ada delta optimized, and optimize to maximizing accuracy\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#   Train the model and test/validate the mode with the test data after each cycle (epoch) through the training data\n",
    "#   Return history of loss and accuracy for each epoch\n",
    "batch_size = 20\n",
    "epochs = 20\n",
    "cbk_early_stopping = EarlyStopping(monitor='val_acc', patience=2, mode='max')\n",
    "\n",
    "hist = model.fit(x_train, y_train,\n",
    "                 batch_size=batch_size,\n",
    "                 epochs=epochs,\n",
    "                 verbose=1,\n",
    "                 validation_data=(x_test, y_test), \n",
    "                 callbacks=[cbk_early_stopping])\n",
    "\n",
    "#   Evaluate the model with the test data to get the scores on \"real\" data.\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 24, 24, 32)\n",
      "(None, 18432)\n",
      "(None, 10)\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.1146 - acc: 0.9663 - val_loss: 0.0714 - val_acc: 0.9780\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.0477 - acc: 0.9857 - val_loss: 0.0502 - val_acc: 0.9839\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 12s 203us/step - loss: 0.0302 - acc: 0.9907 - val_loss: 0.0575 - val_acc: 0.9837\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 0.0197 - acc: 0.9934 - val_loss: 0.0627 - val_acc: 0.9826\n",
      "Test loss: 0.06268864197495859\n",
      "Test accuracy: 0.9826\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dropout, Softmax\n",
    "from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layer=Conv2D(64, kernel_size=(3,3),\n",
    "                       activation='relu',\n",
    "                       input_shape=input_shape))\n",
    "model.add(layer=Conv2D(32, kernel_size=(3,3),\n",
    "                       activation='relu'))\n",
    "print(model.output_shape)\n",
    "model.add(Flatten())\n",
    "print(model.output_shape)\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "print(model.output_shape)\n",
    "\n",
    "#   define compile to minimize categorical loss, use ada delta optimized, and optimize to maximizing accuracy\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#   Train the model and test/validate the mode with the test data after each cycle (epoch) through the training data\n",
    "#   Return history of loss and accuracy for each epoch\n",
    "batch_size = 20\n",
    "epochs = 20\n",
    "cbk_early_stopping = EarlyStopping(monitor='val_acc', patience=2, mode='max')\n",
    "\n",
    "hist = model.fit(x_train, y_train,\n",
    "                 batch_size=batch_size,\n",
    "                 epochs=epochs,\n",
    "                 verbose=1,\n",
    "                 validation_data=(x_test, y_test), \n",
    "                 callbacks=[cbk_early_stopping])\n",
    "\n",
    "#   Evaluate the model with the test data to get the scores on \"real\" data.\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 8942342153330756977\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 11493605629626433446\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 1840248520100869937\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      "]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "local_device_protos = device_lib.list_local_devices()\n",
    "print([x.name for x in local_device_protos if x.device_type == 'GPU'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed Test\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dropout, Softmax\n",
    "from tensorflow.keras.layers import Dense, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(layer=Conv2D(32, kernel_size=(3,3),\n",
    "                       activation='relu',\n",
    "                       input_shape=input_shape))\n",
    "print(model.output_shape)\n",
    "model.add(layer=Conv2D(32, kernel_size=(3,3),\n",
    "                       activation='relu'))\n",
    "print(model.output_shape)\n",
    "model.add(Flatten())\n",
    "print(model.output_shape)\n",
    "model.add(Dropout(0.5))\n",
    "print(model.output_shape)\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "print(model.output_shape)\n",
    "\n",
    "#   define compile to minimize categorical loss, use ada delta optimized, and optimize to maximizing accuracy\n",
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#   Train the model and test/validate the mode with the test data after each cycle (epoch) through the training data\n",
    "#   Return history of loss and accuracy for each epoch\n",
    "batch_size = 20\n",
    "epochs = 20\n",
    "cbk_early_stopping = EarlyStopping(monitor='val_acc', patience=2, mode='max')\n",
    "\n",
    "hist = model.fit(x_train, y_train,\n",
    "                 batch_size=batch_size,\n",
    "                 epochs=epochs,\n",
    "                 verbose=1,\n",
    "                 validation_data=(x_test, y_test), \n",
    "                 callbacks=[cbk_early_stopping])\n",
    "\n",
    "#   Evaluate the model with the test data to get the scores on \"real\" data.\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.6987 - acc: 0.7820 - val_loss: 0.3171 - val_acc: 0.9099\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.3791 - acc: 0.8873 - val_loss: 0.2797 - val_acc: 0.9205\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.3307 - acc: 0.9008 - val_loss: 0.2389 - val_acc: 0.9335\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 72s 1ms/step - loss: 0.2989 - acc: 0.9104 - val_loss: 0.2039 - val_acc: 0.9451\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 74s 1ms/step - loss: 0.2618 - acc: 0.9224 - val_loss: 0.1689 - val_acc: 0.9532\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 75s 1ms/step - loss: 0.2246 - acc: 0.9327 - val_loss: 0.1375 - val_acc: 0.9597\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 71s 1ms/step - loss: 0.1945 - acc: 0.9413 - val_loss: 0.1165 - val_acc: 0.9653\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 72s 1ms/step - loss: 0.1724 - acc: 0.9475 - val_loss: 0.1004 - val_acc: 0.9711\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 72s 1ms/step - loss: 0.1528 - acc: 0.9537 - val_loss: 0.0922 - val_acc: 0.9734\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 72s 1ms/step - loss: 0.1415 - acc: 0.9568 - val_loss: 0.0809 - val_acc: 0.9751\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 72s 1ms/step - loss: 0.1320 - acc: 0.9595 - val_loss: 0.0734 - val_acc: 0.9781\n",
      "Epoch 12/20\n",
      "44260/60000 [=====================>........] - ETA: 18s - loss: 0.1232 - acc: 0.9639"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "#   Train the model and test/validate the mode with the test data after each cycle (epoch) through the training data\n",
    "#   Return history of loss and accuracy for each epoch\n",
    "batch_size = 20\n",
    "epochs = 20\n",
    "cbk_early_stopping = EarlyStopping(monitor='val_acc', patience=2, mode='max')\n",
    "\n",
    "hist = model.fit(x_train, y_train,\n",
    "                 batch_size=batch_size,\n",
    "                 epochs=epochs,\n",
    "                 verbose=1,\n",
    "                 validation_data=(x_test, y_test), \n",
    "                 callbacks=[cbk_early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.1733 - acc: 0.9477 - val_loss: 0.0530 - val_acc: 0.9830\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.0760 - acc: 0.9769 - val_loss: 0.0469 - val_acc: 0.9852\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0593 - acc: 0.9821 - val_loss: 0.0379 - val_acc: 0.9877\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0497 - acc: 0.9846 - val_loss: 0.0388 - val_acc: 0.9871\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0447 - acc: 0.9850 - val_loss: 0.0309 - val_acc: 0.9895\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.0412 - acc: 0.9868 - val_loss: 0.0338 - val_acc: 0.9893\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.0369 - acc: 0.9882 - val_loss: 0.0340 - val_acc: 0.9887\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "#   Train the model and test/validate the mode with the test data after each cycle (epoch) through the training data\n",
    "#   Return history of loss and accuracy for each epoch\n",
    "batch_size = 20\n",
    "epochs = 20\n",
    "cbk_early_stopping = EarlyStopping(monitor='val_acc', patience=2, mode='max')\n",
    "\n",
    "hist = model.fit(x_train, y_train,\n",
    "                 batch_size=batch_size,\n",
    "                 epochs=epochs,\n",
    "                 verbose=1,\n",
    "                 validation_data=(x_test, y_test), \n",
    "                 callbacks=[cbk_early_stopping])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
